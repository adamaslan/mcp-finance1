# Complete Project Structure for Option 2: GCP Free Tier

## üìÅ Full Directory Structure

```
technical-analysis-mcp/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ .gitignore
‚îÇ
‚îú‚îÄ‚îÄ option2-gcp/
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ mcp-server/                          # Local MCP server (bridge to GCP)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ .env.example
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ technical_analysis_mcp/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ server.py                # [CREATED] MCP server with GCP client
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ test_server.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ cloud-run/                           # Cloud Run API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                          # [CREATED] FastAPI application
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ .dockerignore
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ cloud-functions/                     # Cloud Functions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ calculate_indicators/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                      # [CREATED]
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ detect_signals/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                      # [CREATED]
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rank_signals_ai/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                      # [CREATED]
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ daily_summary/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ terraform/                           # Infrastructure as Code
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf                          # [CREATED]
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars.example
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ scripts/                             # Deployment scripts
‚îÇ       ‚îú‚îÄ‚îÄ deploy.sh                        # [CREATED] One-click deployment
‚îÇ       ‚îú‚îÄ‚îÄ init-firestore.py
‚îÇ       ‚îú‚îÄ‚îÄ test-api.sh
‚îÇ       ‚îî‚îÄ‚îÄ cleanup.sh
‚îÇ
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ SETUP.md
    ‚îú‚îÄ‚îÄ ARCHITECTURE.md
    ‚îî‚îÄ‚îÄ TROUBLESHOOTING.md
```

---

## üìÑ All Requirements Files

### 1. MCP Server Requirements
**File**: `option2-gcp/mcp-server/pyproject.toml`

```toml
[build-system]
requires = ["setuptools>=68.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "technical-analysis-mcp-gcp"
version = "2.0.0"
description = "Technical analysis MCP server with GCP backend"
authors = [{name = "Your Name", email = "your.email@example.com"}]
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "mcp>=0.9.0",
    "httpx>=0.25.0",
    "cachetools>=5.0.0",
    "google-cloud-firestore>=2.13.0",
    "google-cloud-pubsub>=2.18.0",
    "google-cloud-storage>=2.10.0"
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-asyncio>=0.21.0",
    "black>=23.0.0",
    "ruff>=0.1.0"
]

[project.scripts]
technical-analysis-mcp = "technical_analysis_mcp.server:main"
```

---

### 2. Cloud Run API Requirements
**File**: `option2-gcp/cloud-run/requirements.txt`

```txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
google-cloud-firestore==2.13.1
google-cloud-storage==2.10.0
google-cloud-pubsub==2.18.4
google-cloud-logging==3.8.0
pydantic==2.5.0
python-dateutil==2.8.2
```

---

### 3. Cloud Function Requirements

#### calculate_indicators
**File**: `option2-gcp/cloud-functions/calculate_indicators/requirements.txt`

```txt
google-cloud-firestore==2.13.1
google-cloud-storage==2.10.0
google-cloud-pubsub==2.18.4
yfinance==0.2.32
pandas==2.1.3
numpy==1.26.2
```

#### detect_signals
**File**: `option2-gcp/cloud-functions/detect_signals/requirements.txt`

```txt
google-cloud-firestore==2.13.1
google-cloud-storage==2.10.0
google-cloud-pubsub==2.18.4
pandas==2.1.3
numpy==1.26.2
```

#### rank_signals_ai
**File**: `option2-gcp/cloud-functions/rank_signals_ai/requirements.txt`

```txt
google-cloud-firestore==2.13.1
google-cloud-pubsub==2.18.4
google-cloud-aiplatform==1.38.0
vertexai==1.38.0
```

---

### 4. Cloud Run Dockerfile
**File**: `option2-gcp/cloud-run/Dockerfile`

```dockerfile
# Use Python 3.11 slim image
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first (for Docker layer caching)
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY main.py .

# Expose port
EXPOSE 8080

# Set environment variables
ENV PORT=8080
ENV PYTHONUNBUFFERED=1

# Run the application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8080"]
```

---

### 5. Cloud Run .dockerignore
**File**: `option2-gcp/cloud-run/.dockerignore`

```
__pycache__
*.pyc
*.pyo
*.pyd
.Python
*.so
*.egg
*.egg-info
dist
build
.env
.venv
venv/
.git
.gitignore
README.md
tests/
.pytest_cache
```

---

### 6. Terraform Variables
**File**: `option2-gcp/terraform/variables.tf`

```hcl
variable "project_id" {
  description = "GCP Project ID"
  type        = string
}

variable "region" {
  description = "GCP Region"
  type        = string
  default     = "us-central1"
}

variable "bucket_name" {
  description = "Cloud Storage bucket name for data"
  type        = string
}

variable "firestore_location" {
  description = "Firestore database location"
  type        = string
  default     = "us-central"
}
```

---

### 7. Terraform Example Variables
**File**: `option2-gcp/terraform/terraform.tfvars.example`

```hcl
project_id  = "technical-analysis-prod"
region      = "us-central1"
bucket_name = "technical-analysis-data"
```

---

### 8. MCP Server .env.example
**File**: `option2-gcp/mcp-server/.env.example`

```bash
# GCP Configuration
USE_GCP=true
GCP_PROJECT_ID=technical-analysis-prod
CLOUD_RUN_URL=https://technical-analysis-api-xyz-uc.a.run.app
BUCKET_NAME=technical-analysis-data

# Optional: Override default region
GCP_REGION=us-central1

# Optional: Gemini API key (if not using Vertex AI)
# GEMINI_API_KEY=your-key-here
```

---

### 9. MCP Server __init__.py
**File**: `option2-gcp/mcp-server/src/technical_analysis_mcp/__init__.py`

```python
"""Technical Analysis MCP Server with GCP Backend"""

__version__ = "2.0.0"
```

---

### 10. Firestore Initialization Script
**File**: `option2-gcp/scripts/init-firestore.py`

```python
#!/usr/bin/env python3
"""
Initialize Firestore with universe lists and sample data
"""

import os
from google.cloud import firestore
from datetime import datetime

PROJECT_ID = os.getenv("GCP_PROJECT_ID", "technical-analysis-prod")

db = firestore.Client(project=PROJECT_ID)

# Universe lists
UNIVERSES = {
    "sp500": [
        "AAPL", "MSFT", "GOOGL", "AMZN", "NVDA", "META", "TSLA", "BRK.B",
        "UNH", "XOM", "JNJ", "JPM", "V", "PG", "MA", "HD", "CVX", "MRK",
        "ABBV", "KO", "AVGO", "PEP", "COST", "WMT", "LLY", "MCD", "TMO",
        "ACN", "ABT", "CSCO", "DHR", "CRM", "ADBE", "NKE", "TXN", "PM",
        "NEE", "DIS", "VZ", "NFLX", "CMCSA", "BMY", "WFC", "INTC", "UPS",
        "AMD", "HON", "QCOM", "UNP", "LIN", "ORCL", "BA", "COP", "IBM"
        # ... add all 500
    ],
    
    "nasdaq100": [
        "AAPL", "MSFT", "GOOGL", "AMZN", "NVDA", "META", "TSLA", "AVGO",
        "COST", "NFLX", "AMD", "PEP", "ADBE", "CSCO", "CMCSA", "TMUS",
        "QCOM", "INTC", "HON", "INTU", "AMGN", "AMAT", "TXN", "BKNG",
        "ADP", "SBUX", "GILD", "MDLZ", "ADI", "ISRG", "LRCX", "REGN"
        # ... add all 100
    ],
    
    "etf_large_cap": [
        "SPY", "VOO", "IVV", "VTI", "QQQ", "DIA", "IWM", "VEA", "VWO",
        "EFA", "IEFA", "AGG", "BND", "VIG", "VYM", "SCHD", "VUG", "VTV"
    ],
    
    "etf_sector": [
        "XLK", "XLF", "XLV", "XLE", "XLY", "XLP", "XLI", "XLB", "XLU",
        "XLRE", "XLC", "VGT", "VFH", "VHT", "VDE", "VCR", "VDC", "VIS"
    ]
}

print("üóÑÔ∏è  Initializing Firestore collections...")

# Create universe collections
for universe_name, symbols in UNIVERSES.items():
    doc_ref = db.collection("universes").document(universe_name)
    doc_ref.set({
        "symbols": symbols,
        "last_updated": datetime.now(),
        "count": len(symbols)
    })
    print(f"‚úÖ Created universe: {universe_name} ({len(symbols)} symbols)")

# Create health check doc
db.collection("_health_check").document("init").set({
    "initialized": True,
    "timestamp": datetime.now(),
    "version": "2.0.0"
})

print("\n‚úÖ Firestore initialization complete!")
print(f"üìä Total universes: {len(UNIVERSES)}")
print(f"üìà Total unique symbols: {len(set([s for symbols in UNIVERSES.values() for s in symbols]))}")
```

---

### 11. API Test Script
**File**: `option2-gcp/scripts/test-api.sh`

```bash
#!/bin/bash
# Test API endpoints

API_URL="${CLOUD_RUN_URL:-http://localhost:8080}"

echo "üß™ Testing Technical Analysis API"
echo "API URL: $API_URL"
echo ""

# Test health endpoint
echo "1. Testing health endpoint..."
curl -s ${API_URL}/health | jq '.'
echo ""

# Test analyze endpoint (async)
echo "2. Testing analyze endpoint..."
curl -s -X POST ${API_URL}/api/analyze \
  -H "Content-Type: application/json" \
  -d '{"symbol": "AAPL", "period": "1mo", "include_ai": true}' \
  | jq '.'
echo ""

# Wait a bit for processing
echo "3. Waiting 10 seconds for analysis to complete..."
sleep 10

# Get signals
echo "4. Getting signals..."
curl -s ${API_URL}/api/signals/AAPL | jq '.'
echo ""

# Test compare endpoint
echo "5. Testing compare endpoint..."
curl -s -X POST ${API_URL}/api/compare \
  -H "Content-Type: application/json" \
  -d '{"symbols": ["AAPL", "MSFT", "GOOGL"]}' \
  | jq '.'
echo ""

echo "‚úÖ API tests complete!"
```

---

### 12. Cleanup Script
**File**: `option2-gcp/scripts/cleanup.sh`

```bash
#!/bin/bash
# Cleanup GCP resources (use with caution!)

PROJECT_ID="${GCP_PROJECT_ID:-technical-analysis-prod}"
REGION="${GCP_REGION:-us-central1}"

echo "‚ö†Ô∏è  WARNING: This will delete all GCP resources!"
read -p "Are you sure? (yes/no): " confirm

if [ "$confirm" != "yes" ]; then
    echo "Cleanup cancelled."
    exit 0
fi

echo "üóëÔ∏è  Cleaning up GCP resources..."

# Delete Cloud Run service
gcloud run services delete technical-analysis-api --region=${REGION} --quiet

# Delete Cloud Functions
gcloud functions delete calculate-indicators --region=${REGION} --gen2 --quiet
gcloud functions delete detect-signals --region=${REGION} --gen2 --quiet
gcloud functions delete rank-signals-ai --region=${REGION} --gen2 --quiet

# Delete Pub/Sub topics
gcloud pubsub topics delete analyze-request --quiet
gcloud pubsub topics delete indicators-complete --quiet
gcloud pubsub topics delete signals-detected --quiet
gcloud pubsub topics delete analysis-complete --quiet
gcloud pubsub topics delete screen-request --quiet

# Delete Cloud Scheduler job
gcloud scheduler jobs delete daily-market-summary --location=${REGION} --quiet

# Delete Cloud Storage bucket (WARNING: deletes all data!)
# gsutil -m rm -r gs://technical-analysis-data

echo "‚úÖ Cleanup complete!"
echo "Note: Firestore database not deleted (do manually if needed)"
```

---

### 13. Main README
**File**: `option2-gcp/README.md`

```markdown
# Technical Analysis MCP Server - GCP Free Tier

Complete technical analysis system with GCP backend, staying within free tier limits.

## Features

- ‚úÖ AI-powered signal ranking with Gemini
- ‚úÖ 150+ technical signals
- ‚úÖ 50+ indicators
- ‚úÖ Persistent caching (30 days)
- ‚úÖ Parallel screening
- ‚úÖ Automated daily reports
- ‚úÖ Historical tracking
- ‚úÖ $0-2/month cost

## Quick Start

### Prerequisites

- GCP account with billing enabled
- gcloud CLI installed
- Python 3.10+
- Claude Desktop

### Installation

1. **Clone repository**
```bash
git clone <repo-url>
cd technical-analysis-mcp/option2-gcp
```

2. **Set GCP project**
```bash
export GCP_PROJECT_ID="your-project-id"
export GCP_REGION="us-central1"
```

3. **Deploy to GCP**
```bash
chmod +x scripts/deploy.sh
./scripts/deploy.sh
```

4. **Install MCP server**
```bash
cd mcp-server
pip install -e .
```

5. **Configure Claude Desktop**

Add to `~/Library/Application Support/Claude/claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "technical-analysis": {
      "command": "python",
      "args": ["-m", "technical_analysis_mcp.server"],
      "env": {
        "USE_GCP": "true",
        "CLOUD_RUN_URL": "https://your-api-url.run.app",
        "GCP_PROJECT_ID": "your-project-id"
      }
    }
  }
}
```

6. **Restart Claude Desktop**

## Usage

In Claude Desktop:

```
Analyze AAPL with AI insights
```

```
Compare tech stocks: AAPL, MSFT, GOOGL, NVDA
```

```
Find oversold stocks from NASDAQ-100
```

## Architecture

See [ARCHITECTURE.md](../docs/ARCHITECTURE.md)

## Monitoring

```bash
# Check usage
gcloud logging read --limit=100

# View quotas
gcloud compute project-info describe --project=$GCP_PROJECT_ID
```

## Cost Estimate

| Service | Free Tier | Monthly Cost |
|---------|-----------|--------------|
| Cloud Run | 2M requests | $0 |
| Cloud Functions | 2M invocations | $0 |
| Firestore | 1GB storage | $0 |
| Cloud Storage | 5GB | $0 |
| Gemini API | Rate limited | $0-2 |
| **Total** | | **$0-2** |

## Troubleshooting

See [TROUBLESHOOTING.md](../docs/TROUBLESHOOTING.md)

## License

MIT
```

---

### 14. .gitignore
**File**: `option2-gcp/.gitignore`

```
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
venv/
env/
ENV/
.venv

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Environment variables
.env
.env.local

# Terraform
*.tfstate
*.tfstate.backup
.terraform/
.terraform.lock.hcl

# GCP
*.json
!terraform.tfvars.example

# Logs
*.log

# OS
.DS_Store
Thumbs.db

# Test coverage
.coverage
htmlcov/
.pytest_cache/
```

---

## üöÄ Deployment Steps

1. **Set up environment**:
```bash
export GCP_PROJECT_ID="your-project-id"
cd option2-gcp
```

2. **Run deployment**:
```bash
chmod +x scripts/deploy.sh
./scripts/deploy.sh
```

3. **Install MCP server**:
```bash
cd mcp-server
pip install -e .
```

4. **Configure Claude Desktop** with output from deploy script

5. **Test in Claude**: "Analyze AAPL with AI insights"

---

## üìä What Gets Created

- ‚úÖ 3 Cloud Functions (calculate, detect, rank)
- ‚úÖ 1 Cloud Run API
- ‚úÖ 5 Pub/Sub topics
- ‚úÖ 1 Cloud Storage bucket
- ‚úÖ 1 Firestore database
- ‚úÖ 1 Cloud Scheduler job
- ‚úÖ Full monitoring & logging

**Total setup time**: ~30 minutes
**Monthly cost**: $0-2 (within free tier)

---

## üéØ Next Steps

All files are now ready! Would you like me to:

1. Create the `daily_summary` Cloud Function?
2. Add more detailed documentation?
3. Create example usage scripts?
4. Add monitoring/alerting setup?

The complete Option 2 (GCP Free Tier) is now ready to deploy! üöÄb