# Technical Analysis Jupyter Notebook - Cell by Cell Guide

## Cell 1: Configuration & Imports

Cell 1 establishes the foundation for the entire technical analysis system by importing all necessary libraries and setting up the global configuration. The cell imports yfinance for fetching stock data, pandas and numpy for data manipulation, datetime for handling timestamps, json for data serialization, and pathlib for file operations. It also configures the optional Gemini AI integration by checking if an API key is provided and attempting to import the google-generativeai library. The cell creates the essential directory structure including folders for signals, indicators, and exports under a main data directory. To implement this cell, you need to install the core dependencies (yfinance, pandas, numpy) using pip, and optionally set a GEMINI_API_KEY environment variable if you want AI-powered signal ranking. The cell suppresses warnings to keep output clean and provides immediate feedback on which features are available based on installed packages.

## Cell 2: Data Fetching & Indicator Calculation

Cell 2 contains the core technical analysis engine with two critical functions: fetch_data() and calculate_indicators(). The fetch_data() function uses yfinance to retrieve historical stock data for any ticker symbol over a specified period, validating that data exists before proceeding. The calculate_indicators() function is the workhorse that computes over 50 technical indicators including various moving averages (SMA and EMA for periods 5, 10, 20, 50, 100, 200), the Relative Strength Index (RSI) using the standard 14-period calculation, MACD with its signal line and histogram, Bollinger Bands with upper and lower bands, Stochastic oscillator, Average Directional Index (ADX) with directional indicators, Average True Range (ATR), volume indicators, On-Balance Volume (OBV), Volume-Weighted Average Price (VWAP), price changes and volatility measures, and distance calculations from key moving averages. To implement this cell, you only need yfinance, pandas, and numpy installed - no additional configuration is required. The functions use vectorized pandas operations for speed and handle edge cases like insufficient data gracefully. This cell processes all raw price data into actionable technical indicators that form the basis for signal detection.

## Cell 3: Trading Signal Detection

Cell 3 implements the detect_signals() function which analyzes the calculated indicators to identify over 40 distinct trading signals across multiple categories. The function examines the most recent price bars to detect patterns including moving average crossovers (Golden Cross and Death Cross between 50-day and 200-day SMAs), price crosses above or below key moving averages, RSI oversold and overbought conditions with multiple severity levels, MACD bullish and bearish crossovers including zero-line crosses, Bollinger Band touches and squeezes indicating potential breakouts, volume spikes at 2x and 3x average levels, volume-confirmed price movements, large percentage gains or losses, 52-week highs and lows, trend strength based on ADX readings, moving average alignment patterns showing strong trends, stochastic oscillator extremes and crossovers, overextended price conditions relative to moving averages, and gap detection for opening price jumps. Each signal is categorized (MA_CROSS, RSI, MACD, VOLUME, etc.) and assigned a strength rating (STRONG BULLISH, BULLISH, NEUTRAL, BEARISH, STRONG BEARISH). To implement this cell, you need the output from Cell 2's indicator calculations. The function uses simple comparative logic to detect these patterns and returns a list of signal dictionaries, each containing the signal name, description, strength, and category. This cell requires no additional dependencies beyond what's already imported.

## Cell 4: AI Signal Ranking

Cell 4 provides intelligent signal prioritization through two ranking methods: AI-powered ranking using Google's Gemini and a rule-based fallback system. The rank_signals_with_ai() function constructs a detailed prompt for Gemini that includes the stock symbol, current market data (price, change, RSI, MACD, ADX), and all detected signals, then asks the AI to score each signal from 1-100 based on actionability, reliability, timing, and risk/reward ratio. The function handles JSON parsing carefully, cleaning up markdown formatting and extracting the valid JSON response, then applies the AI scores to each signal and sorts them by score. The rank_signals_local() function serves as a fallback that uses predefined rules: signals with "EXTREME" strength get 85 points, "STRONG" gets 75, "SIGNIFICANT" gets 65, and basic directional signals get 55, with bonuses added for particularly reliable categories like MA_CROSS and MACD. To implement this cell with AI ranking, you need a Gemini API key from Google AI Studio and the google-generativeai package installed. Without the API key, the system automatically falls back to rule-based ranking which requires no additional setup. The AI ranking adds significant value by considering market context and nuanced signal interpretation, but the rule-based system provides reliable results for users who prefer not to use external APIs.

## Cell 5: Main Analysis Pipeline

Cell 5 ties everything together with the analyze_stock() function, which orchestrates the complete analysis workflow from data fetching through signal ranking. The function takes a stock symbol and time period as inputs, then sequentially calls fetch_data() to retrieve historical prices, calculate_indicators() to compute technical metrics, detect_signals() to identify trading patterns, and either rank_signals_with_ai() or rank_signals_local() to prioritize the findings. It assembles a comprehensive result dictionary containing the stock symbol, timestamp, current price and change, all detected signals (ranked), a summary with total signal counts and average score, key indicator values (RSI, MACD, ADX, volume, Bollinger Bands, Stochastic), and the complete dataframe with all calculated indicators. The function provides progress feedback through print statements, showing each step of the analysis process. To implement this cell, you need all previous cells executed successfully, as it depends on the functions defined in Cells 2, 3, and 4. No additional dependencies are required beyond what's already imported. The result object can be used directly for analysis or passed to export functions in later cells. This cell represents the core user-facing function that most users will interact with, and it's designed to be simple to call while hiding the complexity of the multi-stage analysis process.

## Cell 6: Save & Export Functions

Cell 6 implements comprehensive data persistence and export capabilities with five main functions that handle different output formats and user needs. The save_results() function creates a dated folder structure and saves analysis results in three formats: JSON for complete signal data with metadata, CSV for the full indicator dataset, and a formatted text report for human readability. The export_to_excel() function creates a professional multi-sheet Excel workbook with separate sheets for summary metrics, detailed signals with AI scores and reasoning, and recent indicator values, using openpyxl to generate properly formatted spreadsheets. The export_to_csv() function provides a simpler CSV export focused on signals for easy import into spreadsheet applications. The generate_text_report() function creates a formatted ASCII report with headers, summary statistics, key indicators, and the top 20 signals with scores and reasoning. The analyze_and_save() wrapper function combines the full analysis pipeline with automatic saving, calling analyze_stock() then save_results() and providing a formatted terminal output through display_summary(). To implement this cell, you need openpyxl installed for Excel export functionality (pip install openpyxl). The functions create the necessary directory structure automatically and handle file naming with timestamps to prevent overwrites. All saved files are organized by date for easy historical tracking.

## Cell 7: Comparison & Screening Functions

Cell 7 extends the analysis capabilities to multiple securities with functions for comparison, screening, and batch processing. The compare_stocks() function analyzes multiple symbols in parallel, collecting key metrics (price, change, signal counts, scores, indicators) and presenting them in a sorted DataFrame, then exporting the comparison to CSV for further analysis. The screen_stocks() function filters a universe of symbols based on technical criteria including RSI range, minimum bullish signals, and minimum AI score, making it easy to find stocks matching specific patterns like oversold conditions or strong trends. The batch_analyze() function processes large lists of symbols with built-in rate limiting (configurable delay between requests) to avoid overwhelming the yfinance API, collecting results in a dictionary and providing progress feedback. All three functions include error handling to continue processing even if individual symbols fail. To implement this cell, you only need the functions from previous cells - no additional dependencies are required. The screening function is particularly powerful for finding trading opportunities across large universes like the S&P 500 or NASDAQ 100, and the comparison function helps with relative strength analysis when choosing between similar securities. These functions build on the single-stock analysis from Cell 5 to provide portfolio-level insights.

## Cell 8: Interactive Dashboards

Cell 8 creates rich, interactive visualizations using Plotly to help users explore their analysis results visually. The create_dashboard() function generates a comprehensive four-panel interactive chart with a candlestick price chart overlaid with moving averages (SMA 20, 50, 200) and Bollinger Bands, an RSI panel with overbought (70) and oversold (30) reference lines, a MACD panel showing the MACD line, signal line, and histogram, and a volume panel with colored bars (green for up days, red for down days) and a 20-day moving average. The dashboard is fully interactive with zoom, pan, hover details, and the ability to toggle series on/off. The create_signals_chart() function provides a bar chart showing the distribution of signals across categories, making it easy to see which types of signals are most prevalent. Both functions save the visualizations as standalone HTML files that can be opened in any browser, shared with others, or embedded in reports. To implement this cell, you need plotly installed (pip install plotly). The visualizations are particularly valuable for pattern recognition and confirmation of signals - seeing a Golden Cross on the chart alongside the signal detection provides strong visual confirmation. The HTML export means these charts work anywhere without requiring Python or Jupyter installed.

## Cell 9: Historical Tracking & Trend Analysis

Cell 9 implements functions for comparing current analysis against historical data to identify trends and track signal evolution over time. The load_historical_analysis() function retrieves previously saved analysis from any date using glob pattern matching to find the most recent file for a given day. The compare_historical() function loads the current analysis and compares it against up to 7 days of historical data, calculating average signal counts and scores over the period and determining if the stock's technical picture is improving, declining, or stable based on score changes exceeding thresholds. The track_signal_accuracy() function monitors how frequently specific signals appear over a 30-day period, calculating the signal's frequency as a percentage of trading days and tracking the stock's price alongside signal occurrences to help validate signal reliability. These functions enable users to answer questions like "Is AAPL becoming more bullish?" or "How often does the RSI OVERSOLD signal appear and what happens after?". To implement this cell, you need to have previously run analyses that created saved files in the data/signals directory structure. No additional dependencies are required beyond the standard imports. The historical comparison is particularly valuable for identifying inflection points where a stock's technical setup is changing significantly, and the signal tracking helps build confidence in which signals are most predictive for specific stocks.

## Cell 10: Utilities & Quick Actions

Cell 10 provides convenience functions for common tasks and rapid analysis workflows. The quick_analysis() function performs a complete analysis but outputs only a condensed single-line summary showing symbol, price/change, signal counts, score, and top signal - perfect for quickly scanning multiple stocks. The get_top_signals() function analyzes a stock and returns just the top N signals with their scores and descriptions, ideal when you only care about the highest-priority alerts. The watchlist_summary() function applies quick_analysis() to an entire watchlist of symbols, providing a rapid overview of all positions in a portfolio or monitoring list. The find_signals_by_category() function filters an analysis result to show only signals from a specific category (like RSI or VOLUME), useful when focusing on particular technical aspects. The export_all_formats() function is a convenience wrapper that exports results to all available formats (JSON, CSV, Excel, text report) in a single call. The cleanup_old_data() function manages disk space by deleting analysis files older than a specified number of days (default 30), keeping storage requirements manageable for users running daily analyses. To implement this cell, no additional dependencies are needed - all functions use existing infrastructure from previous cells. These utilities are designed for power users who run analyses frequently and need efficient workflows. The watchlist_summary() is particularly popular for morning market scans, while cleanup_old_data() prevents indefinite data accumulation.

## Cell 11: Advanced Screening & Custom Filters

Cell 11 enables sophisticated screening with custom logic and predefined strategy templates. The advanced_screener() function accepts a custom criteria function, allowing users to define any combination of technical conditions they want to test - the function loops through symbols, runs full analysis on each, applies the user's criteria function, and returns matching stocks sorted by score. Three predefined screener functions demonstrate common strategies: oversold_reversal() finds stocks with RSI below 35, MACD turning positive, and more bullish than bearish signals (classic reversal setup); momentum_breakout() identifies stocks with 2%+ gains on 1.5x volume while RSI is above 50 (continuation pattern); and strong_uptrend() detects aligned moving averages (10>20>50) with ADX above 25 (confirmed trend). The multi_criteria_screen() function provides a more structured approach with explicit parameters for minimum score, RSI range, volume ratio threshold, and trend direction preference. Users can combine any of these criteria or write their own custom functions. To implement this cell, you need the analyze_stock() function from Cell 5 working properly. No additional dependencies are required. The predefined screeners can be used as-is or modified to create custom strategies, and the advanced_screener() framework makes it easy to test complex multi-indicator setups across large stock universes. This is particularly powerful for developing and validating trading strategies systematically.

## Cell 12: Portfolio Analysis & Correlation

Cell 12 shifts from single-stock analysis to portfolio-level insights with three powerful functions. The analyze_portfolio() function takes a list of symbols and optional position weights, analyzes each holding, calculates weighted scores based on position sizes, and produces a portfolio-level report showing each position's contribution to the overall portfolio score - this helps identify which positions are dragging down or boosting portfolio quality. The correlation_analysis() function computes the Pearson correlation matrix between multiple stocks over a specified period (default 3 months), showing which holdings move together (high correlation) and which provide diversification (low correlation) - essential for portfolio construction and risk management. The find_diversification_candidates() function compares a list of candidate stocks against an existing portfolio, calculating each candidate's correlation to the portfolio average and highlighting low-correlation candidates (absolute correlation < 0.5) that would improve diversification. To implement this cell, you need pandas for correlation calculations and the analyze_stock() function from Cell 5. No additional dependencies are required. These functions are invaluable for portfolio managers and serious investors who want to understand not just individual stock quality but how their holdings work together. The correlation analysis can prevent over-concentration in similar stocks, while the diversification finder helps identify true diversifiers rather than just different stocks in the same sector.

## Cell 13: Machine Learning Signal Prediction

Cell 13 introduces optional machine learning capabilities for predicting signal success rates and outcomes. The prepare_ml_features() function extracts 10 key technical indicators from an analysis result (RSI, MACD, MACD signal, ADX, Stochastic K, Bollinger Band position, volume ratio, price change, distance from SMA 20, volatility) and formats them as a feature vector suitable for machine learning models. The build_signal_predictor() function trains a Random Forest classifier on historical data where each data point includes the technical features and an outcome label (1 for profitable, 0 for unprofitable), using scikit-learn's train-test split for validation and reporting the model's accuracy on held-out test data. The predict_signal_success() function applies a trained model to current analysis results, returning a prediction (SUCCESS or FAIL) and a confidence percentage based on the model's probability estimate. To implement this cell, you need scikit-learn installed (pip install scikit-learn) and historical data in the proper format (features + outcomes). The ML component is entirely optional - all other cells work without it. Users need to collect historical predictions and outcomes over time to train a useful model, making this a longer-term enhancement rather than an immediate feature. The Random Forest model was chosen for its robustness and ability to handle non-linear relationships between technical indicators, but users can swap in other algorithms like XGBoost or neural networks if desired.

## Cell 14: Alerts & Notifications

Cell 14 implements a flexible alerting system for monitoring stocks and triggering notifications when conditions are met. The check_alert_conditions() function evaluates a set of user-defined conditions against analysis results, supporting condition types including RSI oversold/overbought thresholds, high AI score thresholds, and large price change thresholds - returning a list of triggered alert messages. The monitor_watchlist() function continuously checks all symbols in a watchlist against alert conditions, collecting and reporting all triggered alerts with the stock symbol, current price, and specific alert descriptions. The create_alert_report() function formats triggered alerts into a clean, timestamped text report suitable for email or logging. These functions enable automated monitoring scenarios like checking for oversold conditions every morning, alerting when high-conviction signals appear, or notifying of unusual price movements. To implement this cell, you only need the analyze_stock() function from Cell 5 - no additional dependencies are required. Users define their alert conditions as simple dictionaries specifying the condition type and threshold. The system is designed to be extended with additional notification methods (email, SMS, Slack, Discord) by users who want to add those integrations. The alerting system is particularly valuable for passive monitoring of large watchlists where manually checking each stock would be impractical.

## Cell 15: Backtesting & Performance Tracking

Cell 15 provides tools for validating signal effectiveness and tracking prediction accuracy over time. The backtest_signal() function performs simple backtesting by looking at historical analyses to find instances where a specific signal appeared, recording the entry price when the signal triggered, checking the price after a specified hold period (default 5 days), calculating the return percentage, and computing win rate and average return statistics across all instances. The track_prediction_accuracy() function loads a JSON file containing historical predictions and actual outcomes, calculates overall accuracy (correct predictions divided by total predictions), and displays statistics including total predictions made, number correct, and accuracy percentage. To implement this cell, you need historical analysis files saved by Cell 6's save_results() function and optionally a predictions.json file tracking past predictions and outcomes. No additional dependencies are    required. The backtesting is simplified compared to professional backtesting systems (no slippage, commissions, or position sizing) but provides valuable insight into which signals have historically been most reliable for specific stocks. Users should accumulate at least 30 days of data before backtesting results become statistically meaningful. The prediction tracking helps identify if the AI ranking is actually improving decision quality over time, creating a feedback loop for continuous improvement.

## Cell 16: Automation & Scheduling

Cell 16 enables hands-off operation through scheduling, external integrations, and automated workflows. The schedule_daily_analysis() function uses APScheduler to run analysis automatically at a specified time each day (default 4:30 PM after market close), processing a predefined watchlist without user intervention - perfect for maintaining up-to-date analysis. The export_to_google_sheets() function integrates with Google Sheets API to automatically append analysis results to a spreadsheet, enabling collaborative review or integration with Google Data Studio dashboards. The create_summary_email() function formats analysis results into an email-ready text body with subject line, suitable for sending via email libraries or copying into email clients. The automated_workflow() function orchestrates a complete end-to-end workflow including analyzing multiple symbols, exporting to selected formats (JSON, Excel, CSV), checking alert conditions and collecting triggered alerts, and generating summary statistics - all in one function call. To implement this cell, you need APScheduler installed for scheduling (pip install apscheduler) and optionally gspread plus oauth2client for Google Sheets integration (pip install gspread oauth2client) along with Google API credentials. The scheduling function is particularly valuable for users who want daily analysis without manual intervention, while the Google Sheets integration enables sharing results with non-technical team members. The automated workflow function can be scheduled with cron, Windows Task Scheduler, or cloud schedulers for completely hands-off operation.