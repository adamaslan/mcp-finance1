# Technical Analysis: Two Architecture Options

## ğŸ¯ Architecture Comparison

| Feature | **Option 1: 100% Free** | **Option 2: GCP Free Tier Maximized** |
|---------|-------------------------|---------------------------------------|
| **Monthly Cost** | $0 | $0-2 |
| **Storage** | In-memory only | Firestore (1GB free) + Cloud Storage (5GB free) |
| **Compute** | Local only | Cloud Run (2M req/mo free) + Cloud Functions |
| **AI Ranking** | Rule-based | Vertex AI Gemini (free tier) |
| **Caching** | 5-min in-memory | Persistent cache in Firestore |
| **Historical Data** | None | 30 days in Cloud Storage |
| **Screening** | Sequential | Parallel Cloud Functions |
| **Pub/Sub** | None | Yes (10GB/mo free) |
| **Monitoring** | None | Cloud Logging (50GB/mo free) |

---

# ğŸŸ¢ OPTION 1: 100% FREE (Pure Local)

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CLAUDE DESKTOP                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ MCP Protocol
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MCP SERVER (Local Python)                      â”‚
â”‚                                                             â”‚
â”‚  Components:                                                â”‚
â”‚  â€¢ yfinance data fetching                                   â”‚
â”‚  â€¢ pandas/numpy calculations                                â”‚
â”‚  â€¢ In-memory LRU cache (5 min TTL)                          â”‚
â”‚  â€¢ Rule-based signal ranking                                â”‚
â”‚  â€¢ All processing local                                     â”‚
â”‚                                                             â”‚
â”‚  No external dependencies                                   â”‚
â”‚  No network calls (except yfinance)                         â”‚
â”‚  No storage costs                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cost: $0 forever
```

## Features

âœ… **Instant Analysis**: 2-3 seconds per stock
âœ… **No Setup**: Just install and run
âœ… **Unlimited Usage**: No quotas or limits
âœ… **Works Offline**: Cache for recent requests
âœ… **Privacy**: All data stays local

## Limitations

âŒ **No Persistence**: Cache clears on restart
âŒ **No Historical Tracking**: Can't compare to yesterday
âŒ **Sequential Screening**: Slower for 100+ symbols
âŒ **Basic Ranking**: Rule-based only (no AI)
âŒ **No Monitoring**: Can't track usage patterns

## When to Use

- Personal use only
- Don't need historical data
- Prefer simplicity over features
- Privacy is critical
- Want zero costs forever

---

# ğŸ”µ OPTION 2: GCP FREE TIER MAXIMIZED

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CLAUDE DESKTOP                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ MCP Protocol
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MCP SERVER (Local Bridge)                      â”‚
â”‚  â€¢ Handles MCP protocol                                     â”‚
â”‚  â€¢ Routes to GCP or local                                   â”‚
â”‚  â€¢ Smart caching strategy                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ HTTPS
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     GCP BACKEND                             â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Cloud Run API (2M req/mo FREE)                     â”‚  â”‚
â”‚  â”‚   â€¢ FastAPI endpoints                                â”‚  â”‚
â”‚  â”‚   â€¢ Smart routing                                    â”‚  â”‚
â”‚  â”‚   â€¢ Request deduplication                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Firestore (1GB FREE)                               â”‚  â”‚
â”‚  â”‚   â€¢ signals/{symbol}/latest (5min cache)             â”‚  â”‚
â”‚  â”‚   â€¢ analysis/{symbol}/history (30 days)              â”‚  â”‚
â”‚  â”‚   â€¢ universes/sp500 (static lists)                   â”‚  â”‚
â”‚  â”‚   â€¢ screener_cache/{criteria_hash} (15min)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Cloud Storage (5GB FREE)                           â”‚  â”‚
â”‚  â”‚   â€¢ daily/{date}/{symbol}-data.csv                   â”‚  â”‚
â”‚  â”‚   â€¢ signals/{date}/{symbol}-signals.json             â”‚  â”‚
â”‚  â”‚   â€¢ reports/weekly/ (summaries)                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Pub/Sub (10GB/mo FREE)                             â”‚  â”‚
â”‚  â”‚   â€¢ analyze-request â†’ Cloud Function                 â”‚  â”‚
â”‚  â”‚   â€¢ batch-screen â†’ Parallel processing               â”‚  â”‚
â”‚  â”‚   â€¢ rank-signals â†’ AI ranking                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Cloud Functions (2M invoc/mo FREE)                 â”‚  â”‚
â”‚  â”‚   â€¢ calculate_indicators()                           â”‚  â”‚
â”‚  â”‚   â€¢ detect_signals()                                 â”‚  â”‚
â”‚  â”‚   â€¢ parallel_screener() (10 concurrent)              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Vertex AI / Gemini (FREE TIER)                     â”‚  â”‚
â”‚  â”‚   â€¢ Signal ranking                                   â”‚  â”‚
â”‚  â”‚   â€¢ Pattern recognition                              â”‚  â”‚
â”‚  â”‚   â€¢ Market insights                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Cloud Logging (50GB/mo FREE)                       â”‚  â”‚
â”‚  â”‚   â€¢ Request tracking                                 â”‚  â”‚
â”‚  â”‚   â€¢ Performance monitoring                           â”‚  â”‚
â”‚  â”‚   â€¢ Error alerting                                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Cloud Scheduler (3 jobs FREE)                      â”‚  â”‚
â”‚  â”‚   â€¢ Daily market summary                             â”‚  â”‚
â”‚  â”‚   â€¢ Weekly top picks                                 â”‚  â”‚
â”‚  â”‚   â€¢ Cache warming                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cost: $0-2/month (within free tiers)
```

## Features

âœ… **AI-Powered Ranking**: Gemini ranks all signals
âœ… **Persistent Cache**: Analysis stored for 30 days
âœ… **Historical Tracking**: Compare today vs yesterday
âœ… **Parallel Screening**: 10x faster for large universes
âœ… **Automated Reports**: Daily summaries via Scheduler
âœ… **Monitoring**: Track usage and performance
âœ… **Scalable**: Handles burst traffic
âœ… **Smart Routing**: Local for simple, GCP for complex

## Free Tier Allocations

### Cloud Run (Always Free)
- **2M requests/month** = 66k/day = 2,750/hour
- **360k vCPU-seconds** = 100 hours compute/month
- **1GB network egress**

### Firestore (Always Free)
- **1GB storage**
- **50k document reads/day** = 1.5M/month
- **20k document writes/day** = 600k/month
- **20k document deletes/day**

### Cloud Storage (Always Free)
- **5GB storage**
- **5GB egress/month**
- **5k Class A operations/month** (writes)
- **50k Class B operations/month** (reads)

### Cloud Functions (Always Free)
- **2M invocations/month**
- **400k GB-seconds compute**
- **200k GHz-seconds compute**
- **5GB egress/month**

### Pub/Sub (Always Free)
- **10GB messages/month**

### Vertex AI Gemini (Free Tier)
- **Varies by region**
- **Rate limits apply**
- **Generous free quota**

### Cloud Logging (Always Free)
- **50GB logs/month**

### Cloud Scheduler (Always Free)
- **3 jobs**

## Staying Within Free Tier

### Request Distribution Strategy

```
Total requests/month target: 50k (well below 2M limit)
â”œâ”€â”€ Simple queries (80%): 40k â†’ Local cache hit
â”œâ”€â”€ Medium queries (15%): 7.5k â†’ Firestore cache hit  
â””â”€â”€ Complex queries (5%): 2.5k â†’ Full GCP pipeline
```

### Storage Strategy

```
Firestore (1GB limit):
â”œâ”€â”€ Hot cache (5min): ~100 symbols Ã— 50KB = 5MB
â”œâ”€â”€ Daily cache (24h): ~500 symbols Ã— 50KB = 25MB
â”œâ”€â”€ Historical (30d): ~500 symbols Ã— 50KB Ã— 30 = 750MB
â””â”€â”€ Metadata: ~50MB
Total: ~830MB (83% of limit)
```

### Compute Budget

```
Cloud Run (360k vCPU-sec/mo):
â”œâ”€â”€ 50k requests Ã— 0.5 sec avg = 25k vCPU-sec
â””â”€â”€ Safety margin: 93% remaining
```

## Advanced Features

### 1. Historical Comparison

```python
# Store daily snapshots
@app.get("/api/compare-history/{symbol}")
async def compare_history(symbol: str, days: int = 7):
    """Compare today's signals vs past week"""
    
    today = await get_analysis(symbol)
    history = []
    
    for i in range(1, days + 1):
        date = (datetime.now() - timedelta(days=i)).strftime("%Y-%m-%d")
        doc = db.collection("analysis").document(symbol).collection("history").document(date).get()
        if doc.exists:
            history.append(doc.to_dict())
    
    return {
        "symbol": symbol,
        "current": today,
        "history": history,
        "trend": calculate_trend(today, history)
    }
```

### 2. Parallel Screening

```python
# Cloud Function: parallel_screener
from concurrent.futures import ThreadPoolExecutor

def parallel_screener(event, context):
    """Screen 100+ symbols in parallel"""
    data = json.loads(base64.b64decode(event['data']))
    symbols = data['symbols']  # e.g., all S&P 500
    criteria = data['criteria']
    
    def analyze_one(symbol):
        # Trigger analysis via Pub/Sub
        publisher.publish(
            topic_path,
            data=json.dumps({"symbol": symbol}).encode()
        )
    
    # Process 10 at a time
    with ThreadPoolExecutor(max_workers=10) as executor:
        executor.map(analyze_one, symbols)
```

### 3. Scheduled Reports

```python
# Cloud Function: daily_summary (triggered by Cloud Scheduler)
def daily_summary(request):
    """Generate daily market summary"""
    
    # Get top movers
    symbols = ["AAPL", "MSFT", "GOOGL", "AMZN", "NVDA"]
    analyses = []
    
    for symbol in symbols:
        doc = db.collection("signals").document(symbol).get()
        if doc.exists:
            analyses.append(doc.to_dict())
    
    # Generate summary
    summary = {
        "date": datetime.now().strftime("%Y-%m-%d"),
        "top_bullish": sorted(analyses, key=lambda x: x['summary']['bullish'], reverse=True)[:3],
        "top_bearish": sorted(analyses, key=lambda x: x['summary']['bearish'], reverse=True)[:3],
        "market_sentiment": calculate_sentiment(analyses)
    }
    
    # Save to Cloud Storage
    bucket = storage_client.bucket(BUCKET_NAME)
    blob = bucket.blob(f"reports/daily/{summary['date']}-summary.json")
    blob.upload_from_string(json.dumps(summary, indent=2))
    
    return summary
```

### 4. AI Signal Ranking

```python
# Cloud Function: rank_signals_ai
from google.cloud import aiplatform
from vertexai.preview.generative_models import GenerativeModel

def rank_signals_ai(event, context):
    """Use Gemini to rank signals"""
    data = json.loads(base64.b64decode(event['data']))
    symbol = data['symbol']
    signals = data['signals']
    
    # Initialize Gemini
    model = GenerativeModel("gemini-2.0-flash-exp")
    
    prompt = f"""
    Expert technical analyst scoring signals for {symbol}.
    
    Score each 1-100 based on:
    - Actionability (can trade on this?)
    - Reliability (historical accuracy)
    - Timing (relevant now?)
    - Risk/reward
    
    Signals:
    {json.dumps(signals, indent=2)}
    
    Return ONLY JSON:
    {{"scores": [{{"signal_number": 1, "score": 85, "reasoning": "..."}}]}}
    """
    
    response = model.generate_content(prompt)
    scores = json.loads(response.text)
    
    # Update Firestore
    for score_item in scores['scores']:
        sig_idx = score_item['signal_number'] - 1
        signals[sig_idx]['ai_score'] = score_item['score']
        signals[sig_idx]['ai_reasoning'] = score_item['reasoning']
    
    # Save ranked signals
    db.collection("signals").document(symbol).set({
        "signals": signals,
        "timestamp": datetime.now(),
        "ranked_by": "gemini-2.0"
    })
```

### 5. Smart Caching Strategy

```python
# MCP Server: Intelligent routing
async def analyze_security(symbol: str, period: str = "1mo"):
    """Smart routing: local cache â†’ Firestore â†’ GCP â†’ yfinance"""
    
    # Level 1: Local in-memory cache (instant)
    cache_key = f"{symbol}:{period}"
    if cache_key in LOCAL_CACHE:
        logger.info(f"âœ… L1 cache hit: {symbol}")
        return LOCAL_CACHE[cache_key]
    
    # Level 2: Firestore cache (fast, persistent)
    doc = db.collection("signals").document(symbol).get()
    if doc.exists and is_cache_valid(doc.to_dict(), ttl=300):
        logger.info(f"âœ… L2 cache hit: {symbol}")
        data = doc.to_dict()
        LOCAL_CACHE[cache_key] = data
        return data
    
    # Level 3: GCP full pipeline (AI ranking)
    logger.info(f"ğŸ”„ L3 cache miss: {symbol} - triggering GCP")
    
    # Trigger async analysis
    response = await call_cloud_run_api(
        endpoint="/api/analyze",
        data={"symbol": symbol, "period": period, "use_ai": True}
    )
    
    return response
```

## Implementation Files

### File Structure

```
technical-analysis-mcp/
â”œâ”€â”€ option1-free/                    # 100% Free version
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ technical_analysis_mcp/
â”‚   â”‚       â””â”€â”€ server.py            # Pure local MCP server
â”‚   â””â”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ option2-gcp/                     # GCP Free Tier version
â”‚   â”œâ”€â”€ mcp-server/                  # Local MCP bridge
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â””â”€â”€ technical_analysis_mcp/
â”‚   â”‚   â”‚       â”œâ”€â”€ server.py        # MCP server with GCP client
â”‚   â”‚   â”‚       â””â”€â”€ gcp_client.py    # GCP API client
â”‚   â”‚   â””â”€â”€ pyproject.toml
â”‚   â”‚
â”‚   â”œâ”€â”€ cloud-run/                   # Cloud Run API
â”‚   â”‚   â”œâ”€â”€ main.py                  # FastAPI application
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ cloud-functions/             # Cloud Functions
â”‚   â”‚   â”œâ”€â”€ calculate_indicators/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ detect_signals/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ rank_signals_ai/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ parallel_screener/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ daily_summary/
â”‚   â”‚       â”œâ”€â”€ main.py
â”‚   â”‚       â””â”€â”€ requirements.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ terraform/                   # Infrastructure as Code
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ firestore.tf
â”‚   â”‚   â”œâ”€â”€ cloud-run.tf
â”‚   â”‚   â”œâ”€â”€ cloud-functions.tf
â”‚   â”‚   â”œâ”€â”€ pubsub.tf
â”‚   â”‚   â””â”€â”€ scheduler.tf
â”‚   â”‚
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ deploy.sh                # One-click deployment
â”‚       â”œâ”€â”€ init-firestore.py        # Initialize Firestore
â”‚       â””â”€â”€ setup-scheduler.sh       # Setup Cloud Scheduler
â”‚
â””â”€â”€ README.md                        # Choose your adventure
```

## Cost Monitoring

### Daily Quotas (GCP Free Tier)

```python
# scripts/check_quotas.py

from google.cloud import monitoring_v3
from datetime import datetime, timedelta

def check_free_tier_usage():
    """Check usage against free tier limits"""
    
    client = monitoring_v3.MetricServiceClient()
    project_name = f"projects/{PROJECT_ID}"
    
    # Check Cloud Run requests
    interval = monitoring_v3.TimeInterval({
        "end_time": {"seconds": int(time.time())},
        "start_time": {"seconds": int((datetime.now() - timedelta(days=1)).timestamp())}
    })
    
    results = client.list_time_series(
        request={
            "name": project_name,
            "filter": 'metric.type="run.googleapis.com/request_count"',
            "interval": interval,
        }
    )
    
    daily_requests = sum(point.value.int64_value for result in results for point in result.points)
    
    print(f"""
    ğŸ“Š Free Tier Usage (Last 24h):
    
    Cloud Run:
    â€¢ Requests: {daily_requests:,} / 66,666 daily ({daily_requests/666.66:.1f}%)
    â€¢ Status: {'âœ… Safe' if daily_requests < 50000 else 'âš ï¸  High'}
    
    Firestore:
    â€¢ Reads: {get_firestore_reads():,} / 50,000 daily
    â€¢ Writes: {get_firestore_writes():,} / 20,000 daily
    
    Cloud Storage:
    â€¢ Usage: {get_storage_usage():.2f} GB / 5 GB
    
    Recommendations:
    {get_recommendations(daily_requests)}
    """)

def get_recommendations(requests):
    if requests > 50000:
        return "âš ï¸  Consider adding more local caching"
    elif requests > 30000:
        return "ğŸ’¡ Usage is moderate, monitor trends"
    else:
        return "âœ… Well within free tier limits"
```

## Deployment

### Option 1: 100% Free (5 minutes)

```bash
# Clone and install
git clone <repo>
cd technical-analysis-mcp/option1-free
pip install -e .

# Configure Claude Desktop
cat >> ~/Library/Application\ Support/Claude/claude_desktop_config.json <<EOF
{
  "mcpServers": {
    "technical-analysis": {
      "command": "python",
      "args": ["-m", "technical_analysis_mcp.server"]
    }
  }
}
EOF

# Restart Claude Desktop
# Done! âœ…
```

### Option 2: GCP Free Tier (30 minutes)

```bash
# Clone
git clone <repo>
cd technical-analysis-mcp/option2-gcp

# Setup GCP project
gcloud projects create technical-analysis-prod
gcloud config set project technical-analysis-prod

# Enable APIs
gcloud services enable \
  run.googleapis.com \
  cloudfunctions.googleapis.com \
  firestore.googleapis.com \
  storage.googleapis.com \
  pubsub.googleapis.com \
  aiplatform.googleapis.com \
  cloudscheduler.googleapis.com

# Deploy using Terraform
cd terraform
terraform init
terraform apply -auto-approve

# Initialize Firestore
python ../scripts/init-firestore.py

# Setup Cloud Scheduler
bash ../scripts/setup-scheduler.sh

# Install MCP server
cd ../mcp-server
pip install -e .

# Configure with GCP endpoint
export CLOUD_RUN_URL=$(gcloud run services describe technical-analysis-api --format='value(status.url)')

cat >> ~/Library/Application\ Support/Claude/claude_desktop_config.json <<EOF
{
  "mcpServers": {
    "technical-analysis": {
      "command": "python",
      "args": ["-m", "technical_analysis_mcp.server"],
      "env": {
        "CLOUD_RUN_URL": "$CLOUD_RUN_URL",
        "USE_GCP": "true"
      }
    }
  }
}
EOF

# Restart Claude Desktop
# Done! âœ…
```

## Feature Comparison

| Feature | Option 1 (Free) | Option 2 (GCP) |
|---------|-----------------|----------------|
| **Setup Time** | 5 min | 30 min |
| **Monthly Cost** | $0 | $0-2 |
| **Analysis Speed** | 2-3 sec | 1-2 sec (cached) |
| **Cache Duration** | 5 min | 30 days |
| **Historical Data** | âŒ | âœ… 30 days |
| **AI Ranking** | âŒ | âœ… Gemini |
| **Parallel Screening** | âŒ | âœ… 10x faster |
| **Daily Reports** | âŒ | âœ… Automated |
| **Monitoring** | âŒ | âœ… Full logs |
| **Scalability** | Local limits | 2M req/mo |
| **Offline Mode** | âœ… (cached) | âŒ (needs GCP) |
| **Privacy** | âœ… 100% local | âš ï¸  Data in GCP |

## Which Should You Choose?

### Choose Option 1 (100% Free) if:
- âœ… You want **zero costs forever**
- âœ… You value **simplicity** over features
- âœ… You don't need **historical tracking**
- âœ… **Privacy** is critical
- âœ… You're okay with **rule-based** ranking
- âœ… You analyze **<50 symbols/day**

### Choose Option 2 (GCP Free Tier) if:
- âœ… You want **AI-powered** insights
- âœ… You need **historical comparisons**
- âœ… You screen **100+ symbols** frequently
- âœ… You want **automated daily reports**
- âœ… You like **monitoring** and **optimization**
- âœ… You might **scale up** later
- âœ… You're comfortable with **GCP** (still free!)

## Next Steps

I can now create:

1. **Complete Option 1** (100% Free)
   - Full server.py with 150+ signals
   - Installation script
   - Testing suite

2. **Complete Option 2** (GCP Free Tier)
   - MCP server with GCP client
   - Cloud Run API
   - All Cloud Functions
   - Terraform deployment
   - Monitoring dashboard

Which would you like me to build first?